{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "AV_cross_Sell_NN.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "5pqM-HydEgMD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split, KFold, StratifiedKFold\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from lightgbm import LGBMClassifier\n",
        "from sklearn.metrics import roc_auc_score\n",
        "import pandas as pd\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "import keras\n",
        "from keras.models import Model\n",
        "from keras.layers import Input,  Dense , concatenate, Reshape, Flatten, BatchNormalization, PReLU, Dropout\n",
        "from keras.models import Sequential\n",
        "from keras.layers.embeddings import Embedding\n",
        "from keras.layers.recurrent import LSTM\n",
        "from keras.layers.wrappers import Bidirectional\n",
        "import numpy as np\n",
        "import tensorflow"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pabqGZ0PE93v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_train = pd.read_csv('train.csv')\n",
        "#replace policy sales 141 and 142 with 145\n",
        "df_test = pd.read_csv('test.csv')"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yhWtdsmrFM3f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_labels = pd.get_dummies(df_train['Response'].values)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1t9VNRONG5fv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_id = df_train.id.values\n",
        "test_id = df_test.id.values\n",
        "df_train.drop(['id'], axis=1, inplace=True)\n",
        "df_test.drop(['id'], axis=1, inplace=True)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0S1msV8zKpBq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "le = LabelEncoder()\n",
        "df_train[\"Gender\"] = le.fit_transform(df_train[\"Gender\"].values)\n",
        "df_test[\"Gender\"] = le.transform(df_test[\"Gender\"].values)\n",
        "\n",
        "le = LabelEncoder()\n",
        "df_train[\"Region_Code\"] = le.fit_transform(df_train[\"Region_Code\"].values)\n",
        "df_test[\"Region_Code\"] = le.transform(df_test[\"Region_Code\"].values)\n",
        "\n",
        "le = LabelEncoder()\n",
        "df_train[\"Vehicle_Age\"] = le.fit_transform(df_train[\"Vehicle_Age\"].values)\n",
        "df_test[\"Vehicle_Age\"] = le.transform(df_test[\"Vehicle_Age\"].values)\n",
        "\n",
        "le = LabelEncoder()\n",
        "df_train[\"Vehicle_Damage\"] = le.fit_transform(df_train[\"Vehicle_Damage\"].values)\n",
        "df_test[\"Vehicle_Damage\"] = le.transform(df_test[\"Vehicle_Damage\"].values)\n",
        "\n",
        "le = LabelEncoder()\n",
        "df_train[\"Policy_Sales_Channel\"] = le.fit_transform(df_train[\"Policy_Sales_Channel\"].values)\n",
        "df_test[\"Policy_Sales_Channel\"] = le.transform(df_test[\"Policy_Sales_Channel\"].values)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KdVXX_C36-_h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_train['Age_premium'] = df_train['Age']/df_train['Annual_Premium']\n",
        "df_test['Age_premium'] = df_test['Age']/df_test['Annual_Premium']"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "chcEx16Z8yCd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_train['Prev_insured_vehicle_damage'] = df_train['Previously_Insured'].astype(str) + \"_\" +  df_train['Vehicle_Damage'].astype(str)\n",
        "df_test['Prev_insured_vehicle_damage'] = df_test['Previously_Insured'].astype(str) + \"_\" + df_test['Vehicle_Damage'].astype(str)\n",
        "\n",
        "le = LabelEncoder()\n",
        "df_train[\"Prev_insured_vehicle_damage\"] = le.fit_transform(df_train[\"Prev_insured_vehicle_damage\"].values)\n",
        "df_test[\"Prev_insured_vehicle_damage\"] = le.transform(df_test[\"Prev_insured_vehicle_damage\"].values)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gd2cacy0Oohh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "s = StandardScaler()\n",
        "\n",
        "df_train[['Age_premium','Age', 'Driving_License','Previously_Insured', 'Annual_Premium','Vintage']] = s.fit_transform(df_train[['Age_premium','Age', 'Driving_License','Previously_Insured', 'Annual_Premium','Vintage']].values)\n",
        "df_test[['Age_premium','Age', 'Driving_License','Previously_Insured', 'Annual_Premium','Vintage']] = s.transform(df_test[['Age_premium','Age', 'Driving_License','Previously_Insured', 'Annual_Premium','Vintage']].values)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g6Ln0C0_3I2U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_train['Age_limit'] = [1 if i<18 or i>65 else 0 for i in df_train['Age'].values]\n",
        "df_test['Age_limit'] = [1 if i<18 or i>65 else 0 for i in df_test['Age'].values]"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U3N5_-gFC7t4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Saves the predictions of provided model\n",
        "def save_preds(model, epoch):\n",
        "  # Create input for the model\n",
        "  preds = model.predict(x = [np.reshape(df_test.Gender.values, (-1,1)),\n",
        "               np.reshape(df_test.Region_Code.values, (-1,1)),\n",
        "               np.reshape(df_test.Prev_insured_vehicle_damage.values, (-1,1)),\n",
        "               np.reshape(df_test.Vehicle_Age.values, (-1,1)),\n",
        "               np.reshape(df_test.Vehicle_Damage.values, (-1,1)),\n",
        "               np.reshape(df_test.Policy_Sales_Channel.values, (-1,1)),\n",
        "               df_test[['Experience','Age', 'Driving_License','Previously_Insured', 'Annual_Premium','Vintage', 'Age_premium', 'Age_limit']]], \n",
        "         verbose = 1)\n",
        "  df_submit = pd.DataFrame({'id':test_id,'Response': preds[:,-1]})\n",
        "  df_submit.to_csv(\"submit_nn_\" + str(epoch) + \".csv\", index=False)\n",
        "\n",
        "\n",
        "class CustomCallback(tensorflow.keras.callbacks.Callback):\n",
        "    def on_epoch_begin(self, epoch, logs=None):\n",
        "      if epoch!=0:\n",
        "        save_preds(self.model, epoch)\n"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vb_qj0htinkp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#find average experience with respect to region code\n",
        "\n",
        "region = df_train['Age'].values\n",
        "region = np.append(region,df_test['Age'].values)\n",
        "\n",
        "ap = df_train['Vehicle_Damage'].values\n",
        "ap = np.append(ap,df_test['Vehicle_Damage'].values)\n",
        "\n",
        "df_temp = pd.DataFrame({'Age':region, 'Vehicle_Damage':ap})\n",
        "\n",
        "k = df_temp.groupby('Age')['Vehicle_Damage'].mean()\n",
        "index = k.index.values\n",
        "values = k.values\n",
        "\n",
        "map_reg = {}\n",
        "\n",
        "for i in range(len(index)):\n",
        "  map_reg[index[i]] = values[i]\n",
        "\n",
        "df_train['Experience'] = df_train['Age'].map(map_reg)\n",
        "df_test['Experience'] = df_test['Age'].map(map_reg)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oMx6s6o7Fe0b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from xgboost import XGBClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        " \n",
        "X_train, Y = df_train.drop([\"Response\"], axis=1).values, df_train[\"Response\"].values\n",
        "X_test = df_test.values\n",
        "Y = df_labels.values"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yNxC3EMhFuXi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "3a912236-f0ec-4b77-8881-0d2f9c2f19a5"
      },
      "source": [
        "tensorflow.random.set_seed(2)\n",
        "session_conf = tensorflow.compat.v1.ConfigProto(intra_op_parallelism_threads=1, inter_op_parallelism_threads=1)\n",
        "sess = tensorflow.compat.v1.Session(graph=tensorflow.compat.v1.get_default_graph(), config=session_conf)\n",
        "tensorflow.compat.v1.keras.backend.set_session(sess)\n",
        "\n",
        "batch_size = 64\n",
        "\n",
        "#categorical inputs\n",
        "inp1 = Input(shape=(1,))\n",
        "inp2 = Input(shape=(1,))\n",
        "inp3 = Input(shape=(1,))\n",
        "inp4 = Input(shape=(1,))\n",
        "inp5 = Input(shape=(1,))\n",
        "inp6 = Input(shape=(1,))\n",
        "\n",
        "\n",
        "# numerical input\n",
        "inp7 = Input(shape=(8,)) \n",
        "#inp7 = Input(shape=(1,))\n",
        "#embedding layers\n",
        "layer1 = Flatten()(Embedding(len(df_train.Gender.unique()), 2*len(df_train.Gender.unique()), trainable=True)(inp1))\n",
        "layer2 = Flatten()(Embedding(len(df_train.Region_Code.unique()),2*len(df_train.Region_Code.unique()), trainable=True)(inp2))\n",
        "layer3 = Flatten()(Embedding(len(df_train.Prev_insured_vehicle_damage.unique()),2*len(df_train.Prev_insured_vehicle_damage.unique()), trainable=True)(inp3))\n",
        "layer4 = Flatten()(Embedding(len(df_train.Vehicle_Age.unique()),2*len(df_train.Vehicle_Age.unique()), trainable=True)(inp4))\n",
        "layer5 = Flatten()(Embedding(len(df_train.Vehicle_Damage.unique()), 2*len(df_train.Vehicle_Damage.unique()), trainable=True)(inp5))\n",
        "layer6 = Flatten()(Embedding(len(df_train.Policy_Sales_Channel.unique()), 2*len(df_train.Policy_Sales_Channel.unique()), trainable=True)(inp6))\n",
        "\n",
        "\n",
        "\n",
        "merge = concatenate([layer1,layer2,layer3,layer4,layer5,layer6,inp7])\n",
        "\n",
        "opt = keras.optimizers.Adam(learning_rate=0.0005)\n",
        "hidden1 = Dense(256, activation='linear')(merge)\n",
        "hidden2 = PReLU()(hidden1)\n",
        "\n",
        "hidden1 = Dense(512, activation='linear')(hidden2)\n",
        "hidden3 = PReLU()(hidden1)\n",
        "\n",
        "hidden1 = Dense(256, activation='linear')(hidden3)\n",
        "hidden1 = PReLU()(hidden1)\n",
        "\n",
        "hidden1 = Dense(128, activation='linear')(concatenate([hidden1, hidden2]))\n",
        "hidden1 = PReLU()(hidden1)\n",
        "\n",
        "output = Dense(2,activation='softmax')(hidden1)\n",
        "model = Model(inputs=[inp1,inp2,inp3,inp4,inp5,inp6,inp7], outputs=output)\n",
        "model.compile(loss = 'categorical_crossentropy', optimizer=opt, metrics='mse')\n",
        "print(model.summary())\n",
        "\n",
        "model.fit(x = [np.reshape(df_train.Gender.values, (-1,1)),\n",
        "               np.reshape(df_train.Region_Code.values, (-1,1)),\n",
        "               np.reshape(df_train.Prev_insured_vehicle_damage.values, (-1,1)),\n",
        "               np.reshape(df_train.Vehicle_Age.values, (-1,1)),\n",
        "               np.reshape(df_train.Vehicle_Damage.values, (-1,1)),\n",
        "               np.reshape(df_train.Policy_Sales_Channel.values, (-1,1)),\n",
        "               df_train[['Experience','Age', 'Driving_License','Previously_Insured', 'Annual_Premium','Vintage', 'Age_premium', 'Age_limit']]], \n",
        "          y = Y, batch_size =batch_size, epochs = 4,  verbose = 1, callbacks=[CustomCallback()])"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"functional_1\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 1)]          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_2 (InputLayer)            [(None, 1)]          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_3 (InputLayer)            [(None, 1)]          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_4 (InputLayer)            [(None, 1)]          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_5 (InputLayer)            [(None, 1)]          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_6 (InputLayer)            [(None, 1)]          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding (Embedding)           (None, 1, 4)         8           input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "embedding_1 (Embedding)         (None, 1, 106)       5618        input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "embedding_2 (Embedding)         (None, 1, 8)         32          input_3[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "embedding_3 (Embedding)         (None, 1, 6)         18          input_4[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "embedding_4 (Embedding)         (None, 1, 4)         8           input_5[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "embedding_5 (Embedding)         (None, 1, 310)       48050       input_6[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "flatten (Flatten)               (None, 4)            0           embedding[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "flatten_1 (Flatten)             (None, 106)          0           embedding_1[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "flatten_2 (Flatten)             (None, 8)            0           embedding_2[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "flatten_3 (Flatten)             (None, 6)            0           embedding_3[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "flatten_4 (Flatten)             (None, 4)            0           embedding_4[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "flatten_5 (Flatten)             (None, 310)          0           embedding_5[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "input_7 (InputLayer)            [(None, 8)]          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "concatenate (Concatenate)       (None, 446)          0           flatten[0][0]                    \n",
            "                                                                 flatten_1[0][0]                  \n",
            "                                                                 flatten_2[0][0]                  \n",
            "                                                                 flatten_3[0][0]                  \n",
            "                                                                 flatten_4[0][0]                  \n",
            "                                                                 flatten_5[0][0]                  \n",
            "                                                                 input_7[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 256)          114432      concatenate[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "p_re_lu (PReLU)                 (None, 256)          256         dense[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 512)          131584      p_re_lu[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "p_re_lu_1 (PReLU)               (None, 512)          512         dense_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_2 (Dense)                 (None, 256)          131328      p_re_lu_1[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "p_re_lu_2 (PReLU)               (None, 256)          256         dense_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_1 (Concatenate)     (None, 512)          0           p_re_lu_2[0][0]                  \n",
            "                                                                 p_re_lu[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_3 (Dense)                 (None, 128)          65664       concatenate_1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "p_re_lu_3 (PReLU)               (None, 128)          128         dense_3[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_4 (Dense)                 (None, 2)            258         p_re_lu_3[0][0]                  \n",
            "==================================================================================================\n",
            "Total params: 498,152\n",
            "Trainable params: 498,152\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "None\n",
            "Epoch 1/4\n",
            "5955/5955 [==============================] - 32s 5ms/step - loss: 0.2683 - mse: 0.0876\n",
            "3970/3970 [==============================] - 9s 2ms/step\n",
            "Epoch 2/4\n",
            "5955/5955 [==============================] - 31s 5ms/step - loss: 0.2654 - mse: 0.0868\n",
            "3970/3970 [==============================] - 9s 2ms/step\n",
            "Epoch 3/4\n",
            "5955/5955 [==============================] - 32s 5ms/step - loss: 0.2645 - mse: 0.0865\n",
            "3970/3970 [==============================] - 8s 2ms/step\n",
            "Epoch 4/4\n",
            "5955/5955 [==============================] - 31s 5ms/step - loss: 0.2641 - mse: 0.0864\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f1f2f8377b8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6lf_oLh_YMMO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "preds = model.predict(x = [np.reshape(df_train.Gender.values, (-1,1)),\n",
        "               np.reshape(df_train.Region_Code.values, (-1,1)),\n",
        "               np.reshape(df_train.Prev_insured_vehicle_damage.values, (-1,1)),\n",
        "               np.reshape(df_train.Vehicle_Age.values, (-1,1)),\n",
        "               np.reshape(df_train.Vehicle_Damage.values, (-1,1)),\n",
        "               np.reshape(df_train.Policy_Sales_Channel.values, (-1,1)),\n",
        "               df_train[['Age', 'Driving_License','Previously_Insured', 'Annual_Premium','Vintage', 'Age_premium', 'Age_limit']]], \n",
        "         verbose = 1)\n",
        "score = roc_auc_score(df_train['Response'].values, preds[:,-1])\n",
        "print(score)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ry0pBiOiKPwl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ab8e16fc-a93f-4e80-95a6-e96c6114dc83"
      },
      "source": [
        "preds = model.predict(x = [np.reshape(df_test.Gender.values, (-1,1)),\n",
        "               np.reshape(df_test.Region_Code.values, (-1,1)),\n",
        "               np.reshape(df_test.Prev_insured_vehicle_damage.values, (-1,1)),\n",
        "               np.reshape(df_test.Vehicle_Age.values, (-1,1)),\n",
        "               np.reshape(df_test.Vehicle_Damage.values, (-1,1)),\n",
        "               np.reshape(df_test.Policy_Sales_Channel.values, (-1,1)),\n",
        "               df_test[['Experience','Age', 'Driving_License','Previously_Insured', 'Annual_Premium','Vintage', 'Age_premium', 'Age_limit']]], \n",
        "         verbose = 1)\n",
        "df_submit = pd.DataFrame({'id':test_id,'Response': preds[:,-1]})\n",
        "df_submit.to_csv(\"submit_nn.csv\", index=False)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "3970/3970 [==============================] - 8s 2ms/step\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}